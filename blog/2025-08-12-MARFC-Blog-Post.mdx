---
title: "Evaluating NextGen’s Performance in the MARFC Region with NGIAB"
description: "A case study on using NextGen in a Box (NGIAB) to assess the NextGen Hydro Framework in the Middle Atlantic River Forecast Center (MARFC) region, comparing its performance with CHPS and NWM 3.0."
slug: nextgen-marfc-performance
authors: [hudson, seann, josh, arpita, james, sifan]
tags: [Blog, NGIAB, MARFC, Hydrology, Modeling, NOAA, NWM, NextGen, CHPS]
---

<div className="margin-bottom--lg" />

The region encompassed by the National Weather Service’s (NWS) Middle Atlantic River Forecast Center (MARFC) sees large variations in the performance of the National Water Model 3.0. NOAA-OWP’s NextGen Hydro Framework could be a potential solution to address these inconsistencies. Cooperative Institute for Research to Operations in Hydrology’s (CIROH) NextGen in a Box (NGIAB) provides an accessible method of running the NextGen Framework, which was used to evaluate NextGen’s performance in the MARFC region.

This study evaluated three operational hydrologic modeling frameworks to support improvements in the National Water Model (NWM). This includes the Community Hydrologic Prediction System (CHPS), National Water Model 3.0 (NWM 3.0), and the NextGen. CHPS is the current operational framework used by NOAA's River Forecast Centers. It incorporates the SNOW-17 model for snowmelt and the Sacramento Soil Moisture Accounting (SAC-SMA) model for runoff generation. The National Water Model 3.0 uses the Noah-MP land surface model coupled with the Weather Research and Forecasting Hydrologic model (WRF-Hydro)[2][3] to simulate hydrological processes across CONUS. NextGen framework in this study includes the baseline models in the Basic Model Interface (BMI) - the Noah-OWP-Modular land surface model and the Conceptual Functional Equivalent (CFE)[2]. After initial runs with NextGen baseline configuration, Noah-OWP-Modular was replaced with SNOW-17 output and simplified Potential Evapotranspiration (PET) values from the MARFC database. The models were calibrated using two objective functions namely Kling-Gupta Efficiency (KGE)[6][7] and Nash-Sutcliffe Efficiency (NSE)[4][5].

The case studies focused on two flashy basins in North-Central Pennsylvania - Westfield and Elkland. These basins provide good locations for comparison due to the presence of USGS stream gages and their unpredictable nature, which is inherent to flashy basins. Additionally, both Westfield and Elkland were sites of catastrophic flooding during Tropical Storm Debby in 2024, which allowed evaluation of the models on a recent extreme flood event. Results from Westfield, PA are shown in the Figure 1.

The simulations executed for the case study are listed below:

- **Uncalibrated CHPS**
- **Calibrated CHPS**
- **Uncalibrated NextGen** (AORC forcings)
- **Uncalibrated NextGen** (MARFC forcings)
- **Calibrated NextGen** (AORC forcings; KGE objective function)
- **Calibrated NextGen** (AORC forcings; NSE objective function)
- **Calibrated NextGen** (MARFC forcings; KGE objective function)
- **National Water Model 3.0**


The researchers observed that the calibrated runs for both NextGen and CHPS improved greatly over uncalibrated runs in both Westfield and Elkland basins. Among the calibrated runs, CHPS marginally outperformed NextGen. Additionally, both the CHPS and NextGen outperformed NWM 3.0 in Westfield basin.

Substitution of SNOW-17 output and simpler PET for the NextGen’s NOAH-OWP reduces calibration time by 50% and produced similar outputs.

However, the models that performed best during calibration did not necessarily perform best during the Hurricane Debby extreme event. This suggests that including a greater number of extreme events in the calibration period is necessary to improve model robustness.

NGIAB served as a critical enabler in this study, allowing for rapid iteration and in-depth exploration of the NextGen framework’s configuration space - evaluation of objective functions, forcing datasets, and baseline models – which would have been significantly more challenging with traditional workflows.


<figure style={{ textAlign:'center', margin:'1.5rem 0' }}>
  <img
    src="/img/blog/2025-08-MARFC/figure1.png"
    alt="Figure 1 (a–c) panels"
    style={{ maxWidth:'100%', height:'auto' }}
  />
  <figcaption style={{ fontSize:'0.95rem', lineHeight:1.6, marginTop:'0.6rem', opacity:0.9 }}>
    <strong>Figure 1</strong><br/>
    a) Nash-Sutcliffe Efficiency (NSE) Metric for simulations from 2007 to 2020.<br/>
    b) Percent Bias and NSE of simulations from 2007 to 2020 generated with different forcings - AORC (referred as NextGen) and MARFC Hourly Operational Grids (referred as NextGen FC).<br/>
    c) Hydrograph of Tropical Storm Debby on 08/09/2024. It is important to note that observed data, denoted by black dots, cuts out halfway through the hydrograph and therefore peak flow was estimated by the USGS to be just under 20,000 cfs, which is nearly double the second largest event on record.
  </figcaption>
</figure>

---

## References

<ol>
  <li>National Oceanic and Atmospheric Administration. <em>Community Hydrologic Prediction System (CHPS) Documentation</em> [Internet]. National Oceanic and Atmospheric Administration; [updated 2024 Nov 26; cited 2025 Jul 28]. Available from: <a href="https://vlab.noaa.gov/web/chps" target="_blank">https://vlab.noaa.gov/web/chps</a></li>

  <li>Araki R, Ogden FL, McMillan HK. Testing Soil Moisture Performance Measures in the Conceptual‐Functional Equivalent to the WRF-Hydro National Water Model. <em>JAWRA Journal of the American Water Resources Association</em>. 2025 Feb;61(1):e70002.</li>

  <li>National Oceanic and Atmospheric Administration. <em>The National Water Model</em> [Internet]. National Water Prediction Service; [cited 2025 Jul 29]. Available from: <a href="https://water.noaa.gov/about/nwm" target="_blank">https://water.noaa.gov/about/nwm</a></li>

  <li>Tijerina‐Kreuzer D, Condon L, FitzGerald K, Dugger A, O’Neill MM, Sampson K, Gochis D, Maxwell R. Continental hydrologic intercomparison project, phase 1: A large‐scale hydrologic model comparison over the continental United States. <em>Water Resources Research</em>. 2021 Jul;57(7):e2020WR028931.</li>

  <li>Moriasi DN, Arnold JG, Van Liew MW, Bingner RL, Harmel RD, Veith TL. Model evaluation guidelines for systematic quantification of accuracy in watershed simulations. <em>Transactions of the ASABE</em>. 2007;50(3):885-900.</li>

  <li>Gupta HV, Kling H, Yilmaz KK, Martinez GF. Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling. <em>Journal of Hydrology</em>. 2009 Oct 20;377(1-2):80-91.</li>

  <li>Vrugt JA, de Oliveira DY. Confidence intervals of the Kling-Gupta efficiency. <em>Journal of Hydrology</em>. 2022 Sep 1;612:127968.</li>
</ol>
